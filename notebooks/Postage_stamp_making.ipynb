{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESC Lamp demo \n",
    "## Catalog extraction\n",
    "This notebook shows how to pull postage stamps to use for strong gravitaional lens searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC2: Generate Postage Stamps (Cutouts) for objects in the Object Catalog\n",
    "\n",
    "Owner: **RÃ©my Joseph** ([@herjy](https://github.com/herjy/DESC-Lamp))\n",
    "<br>Last Verified to Run: **2021-11-22** (by @herjy)\n",
    "\n",
    "This notebook is partly based on the `dm_butler_postage_stamps_for_object_catalogs` notebook by Yao-Yuan Mao and the previous notebooks `dm_butler_postage_stamps` notebook by Michael Wood-Vasey and the Stack Club `ButlerTutorial` by Daniel Perrefort.\n",
    "\n",
    "Light curve extraction follows the `dia_sn_vs_truth` notebook by Michael Wood-Vasey.\n",
    "\n",
    "Here we simply copy what was in Yao-Yuan's notebook and trim it to the usecase of selecting galaxies from cosmoDC2 catalogs with magnitude cuts. The notebook will in fine evolve to incorporate the functions we design to streamline this preselection process.\n",
    "\n",
    "### Logistics\n",
    "This is intended to be runnable at NERSC through the https://jupyter.nersc.gov interface from a local git clone of https://github.com/herjy/DESC-Lamp in your NERSC directory.  But you can also run it wherever, with appropriate adjustment of the 'repo' location to point to a place where you have a Butler repo will all of the images. \n",
    "\n",
    "This notebook uses the `desc-stack-weekly-latest` kernel. Instructions for setting up the proper DESC python kernel can be found here: https://confluence.slac.stanford.edu/x/o5DVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "First we will load the needed modules and DC2 DR6 data sets: object catalogs (with `GCRCatalogs`) and DRP products (with `desc_dc2_dm_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desclamp import postage\n",
    "import galsim\n",
    "import pickle\n",
    "# A few common packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lsst.afw.display.rgb as rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the DC2 Run 2.2i DR6 v2 data. The catalogs and there validation are described here: https://arxiv.org/pdf/2110.03769.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lampion = postage.Candidates(\"2.2i_dr6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the catalog names (including old catalogs) can be found by uncommenting the line below.\n",
    "Information obout these catalogs can be found in the [DC2 data product overview](https://confluence.slac.stanford.edu/display/LSSTDESC/DC2+Data+Product+Overview). The Rubin project's [Data product definition document](https://docushare.lsstcorp.org/docushare/dsweb/Get/LSE-163/LSE-163_DataProductsDefinitionDocumentDPDD.pdf)(DPDD) provides further insight into the content of these catalogs. \n",
    "\n",
    "These are [GCR catalogs](https://github.com/LSSTDESC/gcr-catalogs) that may use slightly different definitions and namings than the one used in Rubin's DPDD. The details for the entries of these catalogs can be found in the [GCR Catalogs SChema description](https://github.com/LSSTDESC/gcr-catalogs/blob/master/GCRCatalogs/SCHEMA.md#schema-for-dc2-object-catalogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to see the available catalogs\n",
    "#print('\\n'.join(sorted(GCRCatalogs.get_available_catalogs(include_default_only=False))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a sample of galaxies based on selection criteria\n",
    "\n",
    "Here we will use arbitrary (actually from [Rojas et al. 2021](https://arxiv.org/pdf/2109.00014.pdf)) selection criteria to extract a few moock patches.\n",
    "\n",
    "To learn what columns are in the object catalogs, refer to [this schema table](https://github.com/LSSTDESC/gcr-catalogs/blob/master/GCRCatalogs/SCHEMA.md#schema-for-dc2-object-catalogs). And sometimes it'd be helpful to look at the [source code](https://github.com/LSSTDESC/gcr-catalogs/blob/master/GCRCatalogs/dc2_object.py#L341)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_galaxy_query = (\"clean\",\n",
    "    \"extendedness == 1\",\n",
    "    \"mag_g_cModel- mag_i_cModel < 5\",\n",
    "    \"mag_g_cModel- mag_i_cModel > 1.8\",\n",
    "    \"mag_g_cModel- mag_r_cModel < 3\",\n",
    "    \"mag_g_cModel- mag_r_cModel > 0.6\",\n",
    "    \"mag_r_cModel < 22.5\",\n",
    "    \"mag_r_cModel > 18\",\n",
    "    \"mag_g_cModel > 20\",\n",
    "    \"mag_i_cModel > 18.2\",\n",
    "    \"snr_g_cModel > 10\",\n",
    "    \"snr_r_cModel > 10\",\n",
    "    \"snr_i_cModel > 10\",\n",
    "    )\n",
    "\n",
    "objects = lampion.catalog_query(bright_galaxy_query, tracts=[4639])\n",
    "print(f\"The query returned {len(objects['tract'])} results. Let's not display them all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting postage stamps\n",
    "\n",
    "Now we need to extract postage stamps of the coadded images. For that we need for each object there coordinates, but also there tact and patch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('lensed_source','rb')\n",
    "lensed_source = pickle.load(file, encoding='bytes')\n",
    "gsobj = galsim.Image(lensed_source)\n",
    "\n",
    "i = int(np.random.rand(1)*9000)\n",
    "cutouts = lampion.make_postage_stamps(objects.loc[i:i+24], cutout_size=45, bands = 'irg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lampion.display_cutouts(cutouts, cutout_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert lensed sources and display\n",
    "\n",
    "Displays the previous images of galaxies with a lensed source injected. Lens and light profiles are arbitrary as well as source colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injected = [cutout.inject(gsobj, (200,250,250)) for cutout in cutouts]\n",
    "\n",
    "lampion.display_cutouts(injected, cutout_size=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "sample = np.array(deepcopy(cutouts))\n",
    "lens_fraction = 0.1\n",
    "l = len(cutouts)\n",
    "select = np.random.rand(int(l*lens_fraction))*l\n",
    "select = select.astype(int)\n",
    "\n",
    "sample[select] = np.array(injected)[select]\n",
    "lampion.display_cutouts(sample, cutout_size=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run classifier on postage stamps\n",
    "\n",
    "This is a place holder attempt at running a classification algorithm on DC2 images. \n",
    "I simply borrowed models trained byt Nesar Ramachandra from his [ml_classification_studies](https://github.com/nesar/ml_classification_studies).\n",
    "\n",
    "This is not properly trained for DC2 images so results are irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = np.load(\"/global/homes/r/remyj/git_repos/ml_classification_studies/cosmoDNN/Classification/trained_models/LensJPG_stack_opti0_loss0_lr0.0005_decay0.0_batch8_epoch450.npy\") \n",
    "from tensorflow import keras\n",
    "path = \"/global/homes/r/remyj/git_repos/ml_classification_studies/cosmoDNN/Classification/trained_models/\"\n",
    "model = keras.models.load_model(path+\"LensJPG_stack_opti0_loss0_lr0.0005_decay0.0_batch8_epoch450.hdf5\")\n",
    "weights = np.load(path+\"LensJPG_stack_opti0_loss0_lr0.0005_decay0.0_batch8_epoch450.npy\")\n",
    "truth = np.ones((len(cutouts),2))\n",
    "truth[::2,0] = 0\n",
    "truth[::2,1] = 0\n",
    "\n",
    "cutout_list = np.array([c.exposure[0].image.array for c in cutouts])\n",
    "model.fit(cutout_list, truth)\n",
    "keras.utils.plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting light curves\n",
    "\n",
    "To search for lensed transients, it is useful to have access to light curves. These are extracted from Difference Imaging Analysis (DIA). We used the scripts provided in the `dia_sn_vs_truth` notebook by Michael Wood-Vasey to produce the following light curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to match the position of objects to sources in the DIA catalogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match on RA, Dec\n",
    "\n",
    "for i in range(len(objects_sel)):\n",
    "    sn_position = SkyCoord(objects.loc[i][\"ra\"], objects.loc[i][\"dec\"], unit='deg')\n",
    "\n",
    "    diaObjects_cat = diaObject.get_quantities(['ra', 'dec', 'diaObjectId'])\n",
    "    diaObject_positions = SkyCoord(diaObjects_cat['ra'], diaObjects_cat['dec'], unit='deg')\n",
    "\n",
    "    idx, sep2d, _ = sn_position.match_to_catalog_sky(diaObject_positions)\n",
    "    \n",
    "    print(f'Index: {idx} is {sep2d.to(u.arcsec)[0]:0.6f} away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaObjects_cat = pd.DataFrame(diaObjects_cat)\n",
    "objects_sel = diaObjects_cat.loc[:36]\n",
    "\n",
    "cutout_size = 100\n",
    "cutout_extent = lsst.geom.ExtentI(cutout_size, cutout_size)\n",
    "id=0\n",
    "for (_, object_this), gs_this in zip(objects_sel.iterrows(), gs):\n",
    "    radec = lsst.geom.SpherePoint(object_this[\"ra\"], object_this[\"dec\"], lsst.geom.degrees)\n",
    "    center = skymap.findTract(radec).getWcs().skyToPixel(radec)\n",
    "    bbox = lsst.geom.BoxI(lsst.geom.Point2I((center.x - cutout_size*0.5, center.y - cutout_size*0.5)), cutout_extent)\n",
    "\n",
    "    cutouts = [butler.get(\"deepCoadd_sub\", bbox=bbox, tract=4839, patch=\"0,0\", filter=band) for band in \"irg\"]\n",
    "    wcs_fits_meta = cutouts[0].getWcs().getFitsMetadata()\n",
    "    image_rgb = rgb.makeRGB(*cutouts)\n",
    "    del cutouts  # let gc save some memory for us\n",
    "\n",
    "    ax = plt.subplot(gs_this, projection=WCS(wcs_fits_meta), label=str(object_this[\"objectId\"]))\n",
    "    ax.imshow(image_rgb, origin='lower')\n",
    "    del image_rgb  # let gc save some memory for us\n",
    "    \n",
    "    for c in ax.coords:\n",
    "        c.set_ticklabel(exclude_overlapping=True, size=10)\n",
    "        c.set_axislabel('', size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lightcurve(df, plot='mag', flux_col_names=None,\n",
    "                    title=None, marker='o', linestyle='none',\n",
    "                    colors=None, label_prefix='',\n",
    "                    **kwargs):\n",
    "    \"\"\"Plot a lightcurve from a DataFrame.\n",
    "    \"\"\"\n",
    "    # At lexigraphical order, if not wavelength order.\n",
    "    # Assume fixed list of filters.\n",
    "    filter_order = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "    if colors is None:\n",
    "        colors = {'u': 'violet', 'g': 'indigo', 'r': 'blue', 'i': 'green', 'z': 'orange', 'y': 'red'}\n",
    "    \n",
    "    if flux_col_names is not None:\n",
    "        flux_col, flux_err_col = flux_col_names\n",
    "    else:\n",
    "        if plot == 'flux':\n",
    "            flux_col = 'psFlux'\n",
    "            flux_err_col = 'psFluxErr'\n",
    "        else:\n",
    "            flux_col = 'mag'\n",
    "            flux_err_col = 'mag_err'\n",
    "        \n",
    "    for filt in filter_order:\n",
    "        this_filter = df.query(f'filter == \"{filt}\"')\n",
    "        if this_filter.empty:\n",
    "            continue\n",
    "        # This if sequence is a little silly.\n",
    "        plot_kwargs = {'linestyle': linestyle, 'marker': marker, 'color': colors[filt],\n",
    "                       'label': f'{label_prefix} {filt}'}\n",
    "        plot_kwargs.update(kwargs)\n",
    "\n",
    "        if flux_err_col in this_filter.columns:\n",
    "            plt.errorbar(this_filter['mjd'], this_filter[flux_col], this_filter[flux_err_col],\n",
    "                         **plot_kwargs)\n",
    "                        \n",
    "        else:\n",
    "            if marker is None:\n",
    "                plt.plot(this_filter['mjd'], this_filter[flux_col], **plot_kwargs)\n",
    "\n",
    "            else:\n",
    "                plot_kwargs.pop('linestyle')\n",
    "                plt.scatter(this_filter['mjd'], this_filter[flux_col], **plot_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel('MJD')\n",
    "\n",
    "    if plot == 'flux':\n",
    "        plt.ylabel('psFlux [nJy]')\n",
    "    else:\n",
    "        # Ensure that y-axis decreases as one goes up\n",
    "        # Because plot_lightcurve could be called several times on the same axis,\n",
    "        # simply inverting is not correct.  We have to reverse a sorted list.\n",
    "        plt.ylim(sorted(plt.ylim(), reverse=True))\n",
    "        plt.ylabel('mag [AB]')\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack-weekly",
   "language": "python",
   "name": "desc-stack-weekly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
